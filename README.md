# Audio-deepfake-detection

Foundation models have become powerful tools for generating text, images, and audio, often outperforming traditional methods. However, their ability to create highly convincing outputs poses significant security risks, particularly in the realm of AI-generated deepfake audio. These advanced techniques can easily bypass existing classifiers designed to distinguish legitimate, human-generated input from malicious manipulations. In this project, we focus on developing efficient and robust methods to detect AI-generated deepfake audio. By analyzing advanced attack strategies and leveraging state-of-the-art machine learning techniques, our goal is to enhance the security and reliability of audio-based systems against deepfake threats.


## Datasets

Dataset Information

The dataset used in this project was sourced from York Universityâ€™s collection of audio datasets:

- [Main Dataset Page](https://bil.eecs.yorku.ca/datasets/)
- [Direct Download: for-rerec.tar.gz](https://www.eecs.yorku.ca/~bil/Datasets/for-rerec.tar.gz)

Dataset Description:

The dataset contains audio samples, both authentic and synthesized, to support research in deepfake audio detection. It is structured to facilitate training and testing of machine learning models.

## Preprocessing

The audio files in the dataset were converted to spectrograms for enhanced model performance. Spectrograms provide a visual representation of the spectrum of frequencies in the audio signals, making them highly suitable for deep learning techniques.


## Model 


## Model results


## Conclusion
